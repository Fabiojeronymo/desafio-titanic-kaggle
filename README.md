# üö¢ Desafio Titanic: Previs√£o de Sobreviventes com Machine Learning

## üéØ Objetivo do Projeto

Este projeto representa minha primeira aplica√ß√£o pr√°tica e completa de um pipeline de Data Science. O objetivo foi utilizar o famoso dataset do Titanic, dispon√≠vel no Kaggle, para construir um modelo de Machine Learning capaz de prever se um passageiro sobreviveu ou n√£o ao desastre.

Mais do que apenas alcan√ßar uma alta acur√°cia, o foco foi aplicar e solidificar os conhecimentos rec√©m-adquiridos em cada etapa do fluxo de trabalho, desde a limpeza e an√°lise dos dados at√© o treinamento, avalia√ß√£o e submiss√£o de um modelo preditivo.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3
* **Bibliotecas Principais:**
    * **Pandas:** Para manipula√ß√£o e limpeza dos dados.
    * **Plotly Express & Matplotlib:** Para visualiza√ß√£o e An√°lise Explorat√≥ria de Dados (EDA).
    * **Scikit-learn:** Para pr√©-processamento (`OneHotEncoder`, `MinMaxScaler`) e para a constru√ß√£o dos modelos de Machine Learning (`DecisionTreeClassifier`, `KNeighborsClassifier`).
* **Ambiente:** Google Colab / Jupyter Notebook

## üìÇ O Pipeline do Projeto

O notebook segue um fluxo de trabalho estruturado, dividido nas seguintes etapas:

1.  **An√°lise Explorat√≥ria de Dados (EDA):**
    * Investiga√ß√£o inicial para entender a estrutura dos dados, identificar valores ausentes e visualizar a distribui√ß√£o das vari√°veis.
    * Cria√ß√£o de gr√°ficos com Plotly para analisar a rela√ß√£o entre as features (como `Sexo`, `Classe` e `Idade`) e a vari√°vel alvo (`Survived`).

2.  **Pr√©-processamento e Limpeza:**
    * Tratamento de valores nulos (imputa√ß√£o) em colunas cr√≠ticas como `Age` e `Fare`.
    * Combina√ß√£o estrat√©gica dos dataframes de treino e teste para garantir consist√™ncia nas transforma√ß√µes.

3.  **Codifica√ß√£o de Vari√°veis Categ√≥ricas:**
    * Aplica√ß√£o do `OneHotEncoder` para transformar vari√°veis categ√≥ricas (`Sex`, `Embarked`, `Pclass`) em um formato num√©rico que o modelo possa entender, utilizando um `ColumnTransformer` para um pipeline organizado.

4.  **Treinamento e Avalia√ß√£o de Modelos:**
    * Divis√£o dos dados em conjuntos de treino e valida√ß√£o para uma avalia√ß√£o justa do desempenho.
    * Treinamento de diferentes modelos de classifica√ß√£o (√Årvore de Decis√£o e KNN).
    * Avalia√ß√£o e compara√ß√£o dos modelos com base na acur√°cia no conjunto de valida√ß√£o para escolher o melhor.

5.  **Gera√ß√£o da Submiss√£o:**
    * Treinamento do modelo campe√£o com todos os dados de treino dispon√≠veis.
    * Gera√ß√£o do arquivo `submission.csv` no formato exigido pela competi√ß√£o do Kaggle.

## ‚ú® Principais Aprendizados

* A import√¢ncia cr√≠tica da **An√°lise Explorat√≥ria** para guiar as decis√µes de pr√©-processamento.
* A diferen√ßa fundamental entre `fit`, `transform` e `fit_transform` e a necessidade de evitar **Data Leakage** ao tratar os dados de treino e teste.
* Como construir um pipeline de transforma√ß√£o robusto com `ColumnTransformer`.
* A import√¢ncia de separar um **conjunto de valida√ß√£o** para avaliar o modelo de forma imparcial e diagnosticar o overfitting.

---
